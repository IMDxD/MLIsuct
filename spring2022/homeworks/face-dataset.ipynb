{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom pathlib import Path, PosixPath\nfrom typing import List\nfrom xml.etree import ElementTree\n\nimport albumentations as A\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics.detection import MAP\nfrom torchvision.ops import nms\nfrom torchvision.transforms import ToTensor\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor, fasterrcnn_resnet50_fpn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-05T10:32:49.019329Z","iopub.execute_input":"2022-05-05T10:32:49.020284Z","iopub.status.idle":"2022-05-05T10:32:57.499050Z","shell.execute_reply.started":"2022-05-05T10:32:49.020165Z","shell.execute_reply":"2022-05-05T10:32:57.498291Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"anno_path = Path(\"../input/face-mask-detection/annotations/\")\nfile_path = Path(\"../input/face-mask-detection/images/\")","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:32:57.500841Z","iopub.execute_input":"2022-05-05T10:32:57.501111Z","iopub.status.idle":"2022-05-05T10:32:57.505734Z","shell.execute_reply.started":"2022-05-05T10:32:57.501074Z","shell.execute_reply":"2022-05-05T10:32:57.504764Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"all_labels = set()\n\nfor xml_file in anno_path.rglob(\"*xml\"):\n    xml = ElementTree.parse(xml_file)\n    for element in xml.findall(\"object\"):\n        label = element.find(\"name\").text\n        all_labels.add(label)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:32:57.507575Z","iopub.execute_input":"2022-05-05T10:32:57.507935Z","iopub.status.idle":"2022-05-05T10:33:00.940475Z","shell.execute_reply.started":"2022-05-05T10:32:57.507824Z","shell.execute_reply":"2022-05-05T10:33:00.939685Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"labels_dict = {label: i for i, label in enumerate(all_labels, start=1)}","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:00.942660Z","iopub.execute_input":"2022-05-05T10:33:00.943071Z","iopub.status.idle":"2022-05-05T10:33:00.947828Z","shell.execute_reply.started":"2022-05-05T10:33:00.943034Z","shell.execute_reply":"2022-05-05T10:33:00.946582Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"labels_dict","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:00.949982Z","iopub.execute_input":"2022-05-05T10:33:00.950454Z","iopub.status.idle":"2022-05-05T10:33:00.962204Z","shell.execute_reply.started":"2022-05-05T10:33:00.950417Z","shell.execute_reply":"2022-05-05T10:33:00.961505Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_transform = A.Compose([\n    A.SmallestMaxSize(224),\n    A.transforms.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2)\n], bbox_params=A.BboxParams(format=\"coco\", label_fields=['category_ids'], min_visibility=0.3))\n\ntest_transform = A.Compose([\n    A.SmallestMaxSize(224),\n], bbox_params=A.BboxParams(format=\"coco\", label_fields=['category_ids'], min_visibility=0.3))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:00.963384Z","iopub.execute_input":"2022-05-05T10:33:00.963667Z","iopub.status.idle":"2022-05-05T10:33:00.971028Z","shell.execute_reply.started":"2022-05-05T10:33:00.963610Z","shell.execute_reply":"2022-05-05T10:33:00.970371Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class DetectionDataset(Dataset):\n    \n    def __init__(self, anno_files: List[PosixPath], file_path, labels_dict, transform=None):\n        self.anno_files = anno_files\n        self.file_path = file_path\n        self.to_tensor = ToTensor()\n        self.labels_dict = labels_dict\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.anno_files)\n    \n    def __getitem__(self, index):\n        anno_file = self.anno_files[index]\n        xml =  ElementTree.parse(anno_file)\n        img_name = xml.find(\"filename\").text\n        img = Image.open(self.file_path / img_name)\n        img = img.convert('RGB')\n        img = np.array(img)\n        labels = []\n        bboxes = []\n        height = img.shape[0]\n        width = img.shape[1]\n        for element in xml.findall(\"object\"):\n            label = element.find(\"name\").text\n            label_id = self.labels_dict[label]\n            labels.append(label_id)\n            bndbox = element.find(\"bndbox\")\n            xmin = int(bndbox.find(\"xmin\").text)\n            ymin = int(bndbox.find(\"ymin\").text)\n            xmax = min(int(bndbox.find(\"xmax\").text), width)\n            ymax = min(int(bndbox.find(\"ymax\").text), height)\n            bboxes.append([xmin, ymin, xmax - xmin, ymax - ymin])\n        if self.transform is not None:\n            img_dict = self.transform(image=img, bboxes=bboxes, category_ids=labels)\n            bboxes = img_dict[\"bboxes\"]\n            img = self.to_tensor(img_dict[\"image\"])\n            labels = torch.LongTensor(img_dict[\"category_ids\"])\n        else:\n            img = self.to_tensor(img)\n            labels = torch.LongTensor(labels)\n        areas = [width * height for _, _, width, height in bboxes]\n        bboxes = [\n            [xmin, ymin, xmin + width, ymin + height]\n            for xmin, ymin, width, height in bboxes\n        ]\n        bboxes = torch.FloatTensor(bboxes)\n        image_id = torch.tensor([index])\n        areas = torch.FloatTensor(areas)\n        return {\n            \"image\": img, \n            \"labels\": labels,\n            \"bndboxes\": bboxes,\n            \"areas\": areas,\n            \"image_id\": image_id\n        }","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:00.972352Z","iopub.execute_input":"2022-05-05T10:33:00.972748Z","iopub.status.idle":"2022-05-05T10:33:00.988600Z","shell.execute_reply.started":"2022-05-05T10:33:00.972713Z","shell.execute_reply":"2022-05-05T10:33:00.987585Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"anno_files = list(anno_path.rglob(\"*xml\"))\nidxs = np.arange(len(anno_files))\nnp.random.seed(0)\ntrain_idxs = np.random.choice(idxs, int(0.8 * len(idxs)), replace=False)\ntest_idxs = [i for i in idxs if i not in train_idxs]","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:00.989906Z","iopub.execute_input":"2022-05-05T10:33:00.990305Z","iopub.status.idle":"2022-05-05T10:33:01.012641Z","shell.execute_reply.started":"2022-05-05T10:33:00.990269Z","shell.execute_reply":"2022-05-05T10:33:01.011996Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_files = [anno_files[i] for i in train_idxs]\ntest_files = [anno_files[i] for i in test_idxs]","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:01.013778Z","iopub.execute_input":"2022-05-05T10:33:01.014096Z","iopub.status.idle":"2022-05-05T10:33:01.018288Z","shell.execute_reply.started":"2022-05-05T10:33:01.014058Z","shell.execute_reply":"2022-05-05T10:33:01.017347Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"len(train_files), len(test_files)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:01.021796Z","iopub.execute_input":"2022-05-05T10:33:01.022088Z","iopub.status.idle":"2022-05-05T10:33:01.029154Z","shell.execute_reply.started":"2022-05-05T10:33:01.022053Z","shell.execute_reply":"2022-05-05T10:33:01.028394Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_dataset = DetectionDataset(train_files, file_path, labels_dict, train_transform)\ntest_dataset = DetectionDataset(train_files, file_path, labels_dict, test_transform)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:01.030698Z","iopub.execute_input":"2022-05-05T10:33:01.031041Z","iopub.status.idle":"2022-05-05T10:33:01.039751Z","shell.execute_reply.started":"2022-05-05T10:33:01.030995Z","shell.execute_reply":"2022-05-05T10:33:01.039045Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = fasterrcnn_resnet50_fpn(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:01.040716Z","iopub.execute_input":"2022-05-05T10:33:01.040907Z","iopub.status.idle":"2022-05-05T10:33:10.589565Z","shell.execute_reply.started":"2022-05-05T10:33:01.040885Z","shell.execute_reply":"2022-05-05T10:33:10.588851Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"in_features = model.roi_heads.box_predictor.cls_score.in_features\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, len(labels_dict) + 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:10.590933Z","iopub.execute_input":"2022-05-05T10:33:10.591208Z","iopub.status.idle":"2022-05-05T10:33:10.596945Z","shell.execute_reply.started":"2022-05-05T10:33:10.591174Z","shell.execute_reply":"2022-05-05T10:33:10.596219Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model.to(\"cuda\");","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:10.598203Z","iopub.execute_input":"2022-05-05T10:33:10.598445Z","iopub.status.idle":"2022-05-05T10:33:15.237972Z","shell.execute_reply.started":"2022-05-05T10:33:10.598412Z","shell.execute_reply":"2022-05-05T10:33:15.237184Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"EPOCHES = 20\nBATCH_SIZE = 6\nLR = 1e-4\nNMS_THRESH = 0.5","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:15.239420Z","iopub.execute_input":"2022-05-05T10:33:15.239675Z","iopub.status.idle":"2022-05-05T10:33:15.244031Z","shell.execute_reply.started":"2022-05-05T10:33:15.239641Z","shell.execute_reply":"2022-05-05T10:33:15.243110Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    images = []\n    targets = []\n    for image_dict in batch:\n        images.append(image_dict[\"image\"])\n        targets.append({\n            \"labels\": image_dict[\"labels\"],\n            \"area\": image_dict[\"areas\"],\n            \"boxes\": image_dict[\"bndboxes\"],\n            \"image_id\": image_dict[\"image_id\"]\n        })\n    return images, targets","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:15.245353Z","iopub.execute_input":"2022-05-05T10:33:15.245617Z","iopub.status.idle":"2022-05-05T10:33:15.255126Z","shell.execute_reply.started":"2022-05-05T10:33:15.245583Z","shell.execute_reply":"2022-05-05T10:33:15.254487Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n\noptimizer = optim.Adam(model.parameters(), LR)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:15.256982Z","iopub.execute_input":"2022-05-05T10:33:15.257412Z","iopub.status.idle":"2022-05-05T10:33:15.264676Z","shell.execute_reply.started":"2022-05-05T10:33:15.257367Z","shell.execute_reply":"2022-05-05T10:33:15.264051Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def fastrcnn_loss(class_logits, box_regression, labels, regression_targets):\n\n    labels = torch.cat(labels, dim=0)\n    regression_targets = torch.cat(regression_targets, dim=0)\n\n    classification_loss = F.cross_entropy(class_logits, labels, weight=[])\n\n    # get indices that correspond to the regression targets for\n    # the corresponding ground truth labels, to be used with\n    # advanced indexing\n    sampled_pos_inds_subset = torch.where(labels > 0)[0]\n    labels_pos = labels[sampled_pos_inds_subset]\n    N, num_classes = class_logits.shape\n    box_regression = box_regression.reshape(N, box_regression.size(-1) // 4, 4)\n\n    box_loss = F.smooth_l1_loss(\n        box_regression[sampled_pos_inds_subset, labels_pos],\n        regression_targets[sampled_pos_inds_subset],\n        beta=1 / 9,\n        reduction=\"sum\",\n    )\n    box_loss = box_loss / labels.numel()\n\n    return classification_loss, box_loss","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:16.447242Z","iopub.execute_input":"2022-05-05T10:33:16.447767Z","iopub.status.idle":"2022-05-05T10:33:16.455321Z","shell.execute_reply.started":"2022-05-05T10:33:16.447724Z","shell.execute_reply":"2022-05-05T10:33:16.454706Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"torchvision.models.detection.roi_heads.fastrcnn_loss = fastrcnn_loss","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:16.456893Z","iopub.execute_input":"2022-05-05T10:33:16.457197Z","iopub.status.idle":"2022-05-05T10:33:16.468406Z","shell.execute_reply.started":"2022-05-05T10:33:16.457161Z","shell.execute_reply":"2022-05-05T10:33:16.467619Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def apply_nms(orig_prediction, iou_thresh):\n\n    keep = nms(orig_prediction['boxes'], orig_prediction['scores'], iou_thresh)\n\n    # Keep indices from nms\n    final_prediction = orig_prediction\n    final_prediction['boxes'] = final_prediction['boxes'][keep]\n    final_prediction['scores'] = final_prediction['scores'][keep]\n    final_prediction['labels'] = final_prediction['labels'][keep]\n\n    return final_prediction","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:16.469925Z","iopub.execute_input":"2022-05-05T10:33:16.470362Z","iopub.status.idle":"2022-05-05T10:33:16.477917Z","shell.execute_reply.started":"2022-05-05T10:33:16.470326Z","shell.execute_reply":"2022-05-05T10:33:16.477277Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"for e in range(EPOCHES):\n    model.train()\n    for i, batch in enumerate(train_loader):\n        optimizer.zero_grad()\n        images, targets = batch\n        images = [image.to(\"cuda\") for image in images]\n        targets = [{k: v.to(\"cuda\") for k, v in targ_dict.items()} for targ_dict in targets]\n        out = model(images, targets)\n        loss = out[\"loss_classifier\"] + out[\"loss_box_reg\"] + out[\"loss_objectness\"] + out[\"loss_rpn_box_reg\"]\n        loss.backward()\n        optimizer.step()\n        if i % 100 == 0:\n            print(f\"Epoch: {e + 1}/{EPOCHES}, iter: {i + 1}/{len(train_loader)}, loss: {loss.item():.3f}\")\n    model.eval()\n    metric = MAP()\n    for batch in test_loader:\n        with torch.no_grad():\n            images, targets = batch\n            images = [image.to(\"cuda\") for image in images]\n            preds = model(images)\n            preds = [apply_nms(p, NMS_THRESH) for p in preds]\n            preds = [{k: v.to(\"cpu\") for k, v in pred_dict.items()} for pred_dict in preds]\n            metric.update(preds, targets)\n    score = metric.compute()\n    print(f\"Epoch: {e + 1}/{EPOCHES}, metric: {score['map']}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-05T10:33:16.480050Z","iopub.execute_input":"2022-05-05T10:33:16.480526Z","iopub.status.idle":"2022-05-05T11:55:11.811775Z","shell.execute_reply.started":"2022-05-05T10:33:16.480492Z","shell.execute_reply":"2022-05-05T11:55:11.811067Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"metric = MAP()\nmodel.eval()\nfor batch in test_loader:\n    with torch.no_grad():\n        images, targets = batch\n        images = [image.to(\"cuda\") for image in images]\n        preds = model(images)\n        preds = [apply_nms(p, NMS_THRESH) for p in preds]\n        preds = [{k: v.to(\"cpu\") for k, v in pred_dict.items()} for pred_dict in preds]\n        metric.update(preds, targets)\nscore = metric.compute()\nprint(f\"metric: {score['map']}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-05T11:57:05.994869Z","iopub.execute_input":"2022-05-05T11:57:05.995565Z","iopub.status.idle":"2022-05-05T11:58:43.845425Z","shell.execute_reply.started":"2022-05-05T11:57:05.995527Z","shell.execute_reply":"2022-05-05T11:58:43.843731Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}