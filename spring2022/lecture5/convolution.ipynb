{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc59a2c-4735-4bb2-8995-12b268844724",
   "metadata": {},
   "source": [
    "# Линейные слои\n",
    "\n",
    "При работе с изображениями на данный момент мы вытягиваем их в вектор и обрабатываем так же как и обычные табличные признаки\n",
    "\n",
    "![](./img/linear.png)\n",
    "\n",
    "Проблема такого подхода кроется в том что мы можем подавать пиксели в любом порядке относительно друг друга и логика обучения/предсказания не будет менятся, наши веса всего лишь сменят индексы.\n",
    "\n",
    "Что же делать?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124c1566-edc6-4754-8b11-1f0871ff747b",
   "metadata": {},
   "source": [
    "# 2. Свертка\n",
    "\n",
    "Давайте введем математическую операцию которая будет учитывать то как располагаются признаки относительно друг друга, скажем мы исследуем какой то процесс во времени и хотим обрабатывать временные признаки по 2 отсчета за раз.\n",
    "\n",
    "число 2 назовем размером ядра свертки\n",
    "\n",
    "![](./img/conv1d.png)\n",
    "\n",
    "Тогда для вектора размером 5, у нас будет 4 шага вычислений, на шагу на каждую соседнюю пару и в результате получим вектор размера 4\n",
    "\n",
    "Это уже больше похоже на то как устроены изображение, наш признак теперь зависит от того какие соседние пиксели попали в свертку, однако пока что мы решили проблему в рамках лево-право, а в изображении есть еще дополнительная размерность вверх-вниз\n",
    "\n",
    "Что же делать?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ba5583-7ca2-475e-badc-42a084e9fbda",
   "metadata": {},
   "source": [
    "# 2D свертка\n",
    "\n",
    "Давайте будем обходить не вектор, а целую матрицу и наша свертка будет не вектором а матрицей, у ядра будет два параметра размер по горизонтали и размер по вертикали и будем обходить изображение слева направо и сверху вниз\n",
    "\n",
    "![](./img/2d_convolution_1.png)\n",
    "\n",
    "Итак мы имеем инструмент чтобы перевести пиксели изображения в карту признаков, однако мы работаем с одной матрицей, а стандартное изображение обычно идет в 3х каналах RGB\n",
    "\n",
    "![](./img/conv.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d13b93-40fc-4f05-aa20-ec2b997eea79",
   "metadata": {},
   "source": [
    "# Padding\n",
    "\n",
    "Как мы можем заметить выходная карта признаков меньше чем исходное изображение, что не всегда хорошо иногда нам нужно сохранять размер карты признаков равной размеру изображения, тогда для этого мы можем добавлять дополнительные края к изображению - padding\n",
    "\n",
    "Существует несколько типов Padding\n",
    "\n",
    "1. Нулевой - добавляем края заполненные нулем\n",
    "2. Зеркальный - отзеркаливаем относительно края\n",
    "3. Краевой - используем соседние значения с краев\n",
    "\n",
    "![](./img/padded.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec03370-c388-4938-946d-802b82ff3809",
   "metadata": {},
   "source": [
    "# Stride\n",
    "\n",
    "Не всегда мы хотим просчитывать все соседние части изображения, иногда мы хотим сильно уменьшить размер карты признаков, для этого шаг делается больше 1\n",
    "\n",
    "![](./img/strided.gif)\n",
    "\n",
    "$$\\large{Size_{new} = (Size_{old} - K + P) / S + 1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424fd83d-72cd-457d-b557-59feb5f2a2ff",
   "metadata": {},
   "source": [
    "# Dilation\n",
    "\n",
    "И последнее изменение обхода связано с тем что расчитывать признак мы можем не хотеть не с соседних пикселей, а с пикселей который равноудаленны на какое то растояние - dilation\n",
    "\n",
    "![](./img/delated.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6777d89b-7531-47e0-8ce1-576c79611dd2",
   "metadata": {},
   "source": [
    "# Сумма сверток\n",
    "\n",
    "Давайте для каждого цвета заведем свое отдельное ядро, рассчитаем карту признаков для каждого цвета и сложим эти карты между собой, прибавив свободный член, так же как и в линейном слое\n",
    "\n",
    "![](./img/conv_channel.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f63d6f-a493-4c5f-8103-2fe06ba42075",
   "metadata": {},
   "source": [
    "# Множество выходов\n",
    "\n",
    "Теперь когда у нас есть параметры:\n",
    "\n",
    "- размеры ядра\n",
    "- количество входных каналов\n",
    "\n",
    "Мы можем добавить дополнительный параметр количество выходных каналов, т.е. мы будем расчитывать множество карт признаков вместо одной\n",
    "\n",
    "![](./img/filters.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9209558b-70f3-43d2-8535-3586682a7b18",
   "metadata": {},
   "source": [
    "# Poolings\n",
    "\n",
    "Иногда для изображений не обязательно считать карту признаков через матрицу, а важно только максимальное/среднее значение, для этой операции существует слой называемый Max/AveragePooling\n",
    "\n",
    "Он работает практически так же как и Convolutional слой, разница лишь в том что в ядре мы берем максимум/среднее и значения по разным каналам не суммируются, т.е. количество выходных каналов равно входным.\n",
    "\n",
    "![](./img/max_pool.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac5fca57-6f62-4982-9da1-e2b889954691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71705ed5-4501-44c2-8fae-c65e92629810",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = nn.Conv2d(\n",
    "    in_channels=3, # вход\n",
    "    out_channels=16, # выход\n",
    "    kernel_size=(3, 3), # размер ядра\n",
    "    stride=(1, 1), # шаг\n",
    "    dilation=(0, 0), # разреженность\n",
    "    padding_mode=\"zeros\", # вставка нулями\n",
    "    padding=(1, 1), # размер отступа\n",
    "    bias=True, # нужен ли свободный член\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58d8c03-ed30-4da9-b1ee-ab899110c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pool_layer = nn.MaxPool2d(\n",
    "    kernel_size=(3, 3), # размер ядра\n",
    "    stride=1, # шаг\n",
    "    dilation=0, # разреженность\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1700bc4-cd3b-4e67-a615-ac6d0e72ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pool_layer = nn.AvgPool2d(\n",
    "    kernel_size=(3, 3), # размер ядра\n",
    "    stride=1, # шаг\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7d11c0-055d-4655-bb00-9464f2f95804",
   "metadata": {},
   "source": [
    "# Backward pass\n",
    "\n",
    "Для сверточного слоя, обратный шаг так же будет сверткой\n",
    "\n",
    "![](./img/back.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2cd8fc-20bd-4bfa-bd3b-c1f2fff61641",
   "metadata": {},
   "source": [
    "# AlexNet\n",
    "\n",
    "В компьютерном зрении проводится основное соревнование, на классификацию изображений на датасете ImageNet\n",
    "\n",
    "ImageNet - это огромный датасет с 1000 классами, задача состоит в том чтобы топ 5 классов предсказанных моделью с наибольшей вероятностью включали в себя истинный класс изображения.\n",
    "\n",
    "До 2014 года качество ручной разметки превосходило все модели которые существовали, однако с появлением сверточных сетей, модель AlexNet смогла побить этот результат\n",
    "\n",
    "![](./img/alexnet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c77e7c5-3803-4aef-8b3c-10aa342fac1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
