{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "748e1936-9cfd-4a5d-87e2-92ddbe1b11b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c1c064-9f4a-4b7a-a127-b72f9e3d0557",
   "metadata": {},
   "source": [
    "![](./img/imagenet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c93344d-e16d-4dfe-acd8-5798af5f5e4e",
   "metadata": {},
   "source": [
    "# 1. Alexnet\n",
    "\n",
    "Мы уже упоминали нейросеть AlexNet в прошлой лекции, когда рассказывали о соревновании ImageNet, где она достигла прорывных для своего времени результатов. Её архитектура состоит из пяти свёрточных слоёв, между которыми располагаются pooling-слои и слои нормализации, а завершают нейросеть три полносвязных слоя.\n",
    "\n",
    "![](./img/alexnet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "958f1df5-b3b7-42c3-bf7e-2852de474f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.alexnet(pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fbea0f-9b9d-4d2a-bb60-64eab714bd95",
   "metadata": {},
   "source": [
    "![](./img/stack_layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654e3ab9-c893-4959-a4f4-542416bac203",
   "metadata": {},
   "source": [
    "# 2. VGG\n",
    "\n",
    "На диаграмме можно видеть, что в 2014 году VGGNet достигла более чем в два раза лучшего результата по сравнению с AlexNet. Основная идея VGG-архитектур — использование большего числа слоёв с фильтрами меньшего размера. Существуют версии VGG-16 и VGG-19 с 16 и 19 слоями соответственно.\n",
    "\n",
    "![](./img/vgg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37619af8-bd66-45f1-a2e5-5c0604cc16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.vgg16(pretrained=False)\n",
    "net = models.vgg16_bn(pretrained=False) # добавили batchnorm\n",
    "\n",
    "net = models.vgg19(pretrained=False)\n",
    "net = models.vgg19_bn(pretrained=False) # добавили batchnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7150bd-8612-4117-a8e9-f5f51f24198b",
   "metadata": {},
   "source": [
    "# 3. Inception (GoogleNet)\n",
    "\n",
    "## 3.1 v1\n",
    "\n",
    "Пререквезит:\n",
    "- Интересуемые классы на изображении могут иметь крайне большую разницу в размерах, например собаки на следующих изображениях\n",
    "\n",
    "![](./img/dog_sizes.jpeg)\n",
    "\n",
    "- Из-за такого огромного разнообразия в расположении информации выбор правильного размера ядра для операции свертки становится затруднительным. Ядро большего размера предпочтительно для классов, которые имеют большой размер, а ядро меньшего размера предпочтительно для классов, которая имеют меньший размер.\n",
    "\n",
    "- Глубокие нейронные сети склонны к переобучению и градиент течет в них гораздо хуже\n",
    "\n",
    "$$\\large{(\\frac{\\partial F_1}{\\partial W_1} < 1)(\\frac{\\partial F_2}{\\partial W_2} < 1) \\dots (\\frac{\\partial F_N}{\\partial W_N} < 1)}$$\n",
    "\n",
    "- Простое добавление сверточных слоев ведет к большому потреблению вычислительных ресурсов\n",
    "\n",
    "\n",
    "Решение:\n",
    "Давайте сделаем несколько сверток которые работают на одном уровне с разными ядрами\n",
    "\n",
    "![](./img/inception1.png)\n",
    "\n",
    "## 3.2 v2\n",
    "\n",
    "Можно ли как то еще уменьшить вычислительную сложность, давайте обратим внимание на то что свертка 5х5 имеет такую же карту признаков как и 2 последовательные свертки 3х3, только вместо 25 параметров в ядре, у нас будет 2 по 9 = 18\n",
    "\n",
    "![](./img/inception2_pre.png)\n",
    "\n",
    "А теперь заметим что свертку 3х3 можно разложить как две свертки 1х3 и 3х1 и получить 6 параметров вместо 18\n",
    "\n",
    "![](./img/inception2.png)\n",
    "\n",
    "![](./img/googlenet.png)\n",
    "\n",
    "## 3.3 v3\n",
    "\n",
    "- Теже блоки что у 2й версии\n",
    "- BatchNorm + Dropout в классификаторе\n",
    "- LabelSmoothing в лосс функции\n",
    "\n",
    "$$\\large{y_{smooth} = (1 - \\alpha) y_{one\\_hot} + \\frac{\\alpha}{C}}$$\n",
    "\n",
    "- C - число классов\n",
    "- $y_{one\\_hot}$ - наш one hot вектор ответа\n",
    "- $\\alpha$ - параметр размытия от 0 до 1, в 0 - стандартная cross entropy в 1 все классы равновероятны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8908009-9695-4442-ae08-35383947511d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imd/miniconda3/envs/mlisuct/lib/python3.8/site-packages/torchvision/models/inception.py:81: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn('The default weight initialization of inception_v3 will be changed in future releases of '\n"
     ]
    }
   ],
   "source": [
    "net = models.inception_v3(pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be50912-dddf-4920-baf1-2d4b003d12fd",
   "metadata": {},
   "source": [
    "# 4 DenseNet\n",
    "\n",
    "DenseNet это очередная архитектура сверточной сети, она использует dense связи между слоями, через имплементацию Dense Blocks, в котором мы соеденяем все слои (с сохранением размеров крат признаков) напрямую друг с другом. Чтобы сохранить природу прямого прохождения, каждый слой получает дополнительные входные данные от всех предыдущих слоев и передает свои собственные карты признаков всем последующим слоям. Мотивация схожа с inception - мы пытаемся сохранить информацию о более маленьких объектах и облегчить течение градиента\n",
    "\n",
    "\n",
    "## 4.1 DenseBlock \n",
    "\n",
    "Это блок в котором реализована dense связь между слоями, каждый вход предыдущего слоя конкатенируется с входом текущего слоя в блоке, если у нас имеется L блоков, тогда количество соедениний в нем будет равно:\n",
    "\n",
    "$$\\large{\\frac{L(L+1)}{2}}$$\n",
    "\n",
    "![](./img/dense_block.png)\n",
    "\n",
    "![](./img/densenet.ppm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3d49517-c1ed-436b-aa92-f140a8fdd40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.densenet121(pretrained=False)\n",
    "net = models.densenet201(pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66369474-0c15-401c-9aa3-2806c8acddda",
   "metadata": {},
   "source": [
    "# 5 ResNet\n",
    "\n",
    "В декабре 2015-го, примерно в то же время, как была представлена архитектура Inception v3, произошла революция — опубликовали ResNet. В ней заложены простые идеи: подаём выходные данные двух успешных свёрточных слоёв И обходим входные данные для следующего слоя\n",
    "\n",
    "![](./img/resnet_block.jpg)\n",
    "\n",
    "Такие идеи уже предлагались, например, <a href=\"http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf\">здесь</a>. Но в данном случае авторы обходят ДВА слоя и применяют подход в больших масштабах. Обход одного слоя не даёт особой выгоды, а обход двух — ключевая находка. Это можно рассматривать как маленький классификатор, как сеть-в-сети!\n",
    "\n",
    "Также это был первый в истории пример обучения сети из нескольких сотен, даже тысячи слоёв.\n",
    "В многослойной ResNet применили bottleneck-слой, аналогичный тому, что применяется в Inception:\n",
    "\n",
    "![](./img/bottleneck.jpg)\n",
    "\n",
    "Этот слой уменьшает количество свойств в каждом слое, сначала используя свёртку 1х1 с меньшим выходом (обычно четверть от входа), затем идёт слой 3х3, а потом опять свёртка 1х1 в большее количество свойств. Как и в случае с Inception-модулями, это позволяет экономить вычислительные ресурсы, сохраняя богатство комбинаций свойств. Сравните с более сложными и менее очевидными stem-ами в Inception V3\n",
    "\n",
    "В небольших resnet до resnet52 не используется хак с уменьшением признаков в блоке\n",
    "\n",
    "![](./img/resnet18.png)\n",
    "\n",
    "В больших resnet начиная с resnet101 используется хак\n",
    "\n",
    "![](./img/resnet101.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19abf84e-e5bd-413b-a8b1-a1841d9315fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.resnet50(pretrained=False)\n",
    "net = models.resnet101(pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc14888-e1ee-41cf-80c5-8e377e985f22",
   "metadata": {},
   "source": [
    "# 6. Se-ResNet\n",
    "\n",
    "Не все признаки одинаково важны, поэтому давайте будем взвешивать наши признаки после ResNet блока с помощью Sigmoid (применяем global pooling - берем максимум в каждом канале от всей карты признаков). И далее выход Resnet мы взвесим по нашим выходам из Sigmoid\n",
    "\n",
    "![](./img/se_resnet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bba7971c-2a29-42d1-8448-21e5925e7cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# данной модели нет в torchvision но можно заменить bootleneck самому"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2067d3b-b2cd-4973-a47b-a997f14d9494",
   "metadata": {},
   "source": [
    "# 7 ResNext\n",
    "\n",
    "ResNeXt блок состоит из повторяющихся частей которые объединяют набор преобразований с одной и той же топологией. В сравнении ResNet, у нас появляется новое измерение - кардинальность (размер набора преобразований) C в качестве важного фактора в дополнение к измерениям глубины и ширины.\n",
    "\n",
    "![](./img/resnext.png)\n",
    "\n",
    "$$\\large{resnet\\_features = 256 \\cdot 1 \\cdot 1 \\cdot 64 + 64 \\cdot 3 \\cdot 3 \\cdot 64 + 64 \\cdot 1 \\cdot 1 \\cdot 256 = 69632}$$\n",
    "$$\\large{resnext\\_features = 256 \\cdot 1 \\cdot 1 \\cdot 4 \\cdot 32 + 4 \\cdot 3 \\cdot 3 \\cdot 4 \\cdot 32 + 4 \\cdot 1 \\cdot 1 \\cdot 256 \\cdot 32 = 70144}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f308ed1b-317b-425f-a64b-e49821de6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.resnext50_32x4d(pretrained=False, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c11805-39f0-4318-b9c8-391f32b189f2",
   "metadata": {},
   "source": [
    "# 8. Se-ResNext\n",
    "\n",
    "Объеденяем идеи resnext и se-resnet\n",
    "\n",
    "![](./img/se_resnext.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0687fdb-0771-437b-84db-43d31262dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель отсутсвует по причине отсутствия se блока"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
