{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a287e364-4680-4e59-a3d5-747879d472b8",
   "metadata": {},
   "source": [
    "# Instance Segmentation\n",
    "\n",
    "- Если объекты не “касаются” и не перекрывают друг друга, их можно разделить\n",
    "- Но так бывает не всегда\n",
    "\n",
    "<img src=\"./img/comb_masks.ppm\">\n",
    "\n",
    "- Добавим в детектор объектов семантическую сегментацию для бокса вокруг каждого объекта"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fa2103-9faf-422f-8f3e-022e897686aa",
   "metadata": {},
   "source": [
    "## Mask R-CNN (2017)\n",
    "\n",
    "- <a href=\"https://paperswithcode.com/paper/mask-r-cnn\">Mask R-CNN (2017)</a>\n",
    "- В основе - Faster R-CNN\n",
    "- Дополнительная ветвь для предсказания бинарной маски во всех proposals\n",
    "- Маски не зависят от классов (т.е. сегментация на 1 класс)\n",
    "- Вместо RoIPool — RoIAlign\n",
    "\n",
    "<img src=\"./img/mask_rcnn.png\">\n",
    "\n",
    "- В Mask R-CNN используется операция RoIAlign: вместо грубого округления границ и пулинга значений используется интерполяция значений по сетке\n",
    "\n",
    "<img src=\"./img/roi_align.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a78195e0-e52f-46b4-bc1e-5ab15a048d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.detection.mask_rcnn import maskrcnn_resnet50_fpn_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d6e14e-d8f9-4834-8662-0aed298bc3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = maskrcnn_resnet50_fpn_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e67502a9-0e37-49ee-87c3-beb7eecf2b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf847e2b-d38e-4955-a7e9-a9d2147360de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([[6.1559e+02, 4.2027e+02, 6.4000e+02, 4.2075e+02],\n",
       "          [2.7607e+02, 9.8405e+01, 3.1026e+02, 9.8812e+01],\n",
       "          [6.1283e+02, 3.5579e+02, 6.3871e+02, 3.5610e+02],\n",
       "          [0.0000e+00, 2.0323e+01, 5.7498e+02, 2.2800e+01],\n",
       "          [2.1118e+02, 1.9843e+01, 6.4000e+02, 2.2970e+01],\n",
       "          [6.1163e+02, 2.8137e+02, 6.4000e+02, 2.8168e+02],\n",
       "          [0.0000e+00, 1.9092e+01, 2.6600e+02, 2.1855e+01],\n",
       "          [0.0000e+00, 8.0917e+00, 3.3582e+02, 1.1736e+01],\n",
       "          [3.8213e+00, 1.5625e+01, 5.0131e+02, 1.8273e+01],\n",
       "          [7.1967e+00, 2.3349e+01, 5.2017e+02, 2.5705e+01],\n",
       "          [0.0000e+00, 5.7343e+00, 2.7185e+02, 9.1125e+00],\n",
       "          [0.0000e+00, 1.8124e+01, 3.8299e+02, 2.1308e+01],\n",
       "          [0.0000e+00, 1.8592e+00, 5.4723e+02, 5.3372e+00],\n",
       "          [1.7067e+02, 3.8817e+02, 2.0382e+02, 3.8872e+02],\n",
       "          [0.0000e+00, 2.2451e+01, 3.9736e+02, 2.4966e+01],\n",
       "          [0.0000e+00, 2.4263e+01, 4.2138e+02, 2.6798e+01],\n",
       "          [2.1355e+02, 1.4653e+02, 2.4398e+02, 1.4688e+02],\n",
       "          [6.0534e+02, 2.0771e+02, 6.3520e+02, 2.0797e+02],\n",
       "          [4.5579e+02, 3.1518e+02, 4.8852e+02, 3.1553e+02],\n",
       "          [1.4961e+02, 8.5229e+01, 4.5655e+02, 8.7674e+01],\n",
       "          [0.0000e+00, 2.2004e+00, 3.1960e+02, 6.4068e+00],\n",
       "          [3.4980e+02, 2.6355e+02, 3.8157e+02, 2.6384e+02],\n",
       "          [3.7945e+02, 1.1538e+02, 4.0558e+02, 1.1570e+02],\n",
       "          [1.1939e+02, 8.8758e+01, 5.2015e+02, 9.1077e+01],\n",
       "          [1.6056e+02, 3.3442e+02, 1.9135e+02, 3.3478e+02],\n",
       "          [4.7814e+02, 3.4552e+02, 5.0301e+02, 3.4595e+02],\n",
       "          [3.3683e+02, 4.1998e+02, 3.6759e+02, 4.2039e+02],\n",
       "          [0.0000e+00, 2.5896e+01, 3.8041e+02, 2.8572e+01],\n",
       "          [3.3887e+02, 4.2168e+02, 3.7034e+02, 4.2203e+02],\n",
       "          [1.9645e+01, 4.1033e-01, 5.0367e+02, 4.4645e+00],\n",
       "          [2.2403e+02, 3.2486e+02, 6.4000e+02, 3.2840e+02],\n",
       "          [6.1100e+02, 2.0409e+02, 6.4000e+02, 2.0437e+02],\n",
       "          [5.7295e+02, 3.7800e+02, 6.1582e+02, 3.7830e+02],\n",
       "          [0.0000e+00, 1.9620e+01, 4.1782e+02, 2.2158e+01],\n",
       "          [0.0000e+00, 1.6751e+01, 5.2759e+02, 1.9135e+01],\n",
       "          [2.5252e+02, 9.5210e+00, 5.9668e+02, 1.2951e+01],\n",
       "          [3.8002e+02, 4.1328e+02, 4.1743e+02, 4.1369e+02],\n",
       "          [2.0795e+02, 2.3943e+02, 2.5236e+02, 2.3983e+02],\n",
       "          [2.1493e+02, 1.4697e+02, 2.4830e+02, 1.4723e+02],\n",
       "          [1.0683e+02, 5.3347e+01, 1.5014e+02, 5.3619e+01],\n",
       "          [5.0006e+02, 4.1720e+02, 5.3939e+02, 4.1772e+02],\n",
       "          [0.0000e+00, 1.4137e+02, 2.4799e+02, 1.4449e+02],\n",
       "          [6.1347e+02, 2.6880e+02, 6.4000e+02, 2.6908e+02],\n",
       "          [0.0000e+00, 0.0000e+00, 3.5778e+02, 2.0876e+00],\n",
       "          [0.0000e+00, 1.1449e+01, 5.8958e+02, 1.4028e+01],\n",
       "          [4.9387e+02, 3.8231e+02, 5.2104e+02, 3.8275e+02],\n",
       "          [0.0000e+00, 3.1554e+02, 3.2804e+02, 3.1914e+02],\n",
       "          [2.4309e+02, 1.4221e+01, 6.3779e+02, 1.6979e+01],\n",
       "          [0.0000e+00, 1.4124e+01, 4.0053e+02, 1.7849e+01],\n",
       "          [1.6306e+02, 3.8423e+02, 1.8980e+02, 3.8463e+02],\n",
       "          [1.0678e+02, 2.1592e+02, 5.7536e+02, 2.1832e+02],\n",
       "          [2.1040e+02, 2.5689e+02, 2.4569e+02, 2.5729e+02],\n",
       "          [4.5257e+02, 2.1613e+02, 4.7492e+02, 2.1664e+02],\n",
       "          [3.8070e+02, 1.2487e+02, 4.0907e+02, 1.2515e+02],\n",
       "          [3.1032e+02, 3.5832e+02, 3.3220e+02, 3.5872e+02],\n",
       "          [0.0000e+00, 3.8700e+00, 2.8967e+02, 7.6540e+00],\n",
       "          [2.7225e+02, 1.5217e+02, 3.0264e+02, 1.5255e+02],\n",
       "          [3.8491e+02, 3.5458e+02, 4.0778e+02, 3.5492e+02],\n",
       "          [3.7310e+02, 1.5234e+00, 6.4000e+02, 7.0693e+00],\n",
       "          [0.0000e+00, 1.0878e+02, 3.4318e+02, 1.1101e+02],\n",
       "          [1.8459e+02, 1.7143e+01, 6.4000e+02, 1.9560e+01],\n",
       "          [3.5914e+02, 3.9163e+02, 3.8747e+02, 3.9189e+02],\n",
       "          [2.8183e+02, 1.7770e+01, 6.4000e+02, 2.0885e+01],\n",
       "          [2.5623e+02, 4.2515e+02, 2.8633e+02, 4.2550e+02],\n",
       "          [3.2990e+02, 7.6288e+00, 6.4000e+02, 1.1429e+01],\n",
       "          [2.2749e+02, 2.4443e+02, 2.5591e+02, 2.4489e+02],\n",
       "          [0.0000e+00, 1.0489e+01, 3.5615e+02, 1.4957e+01],\n",
       "          [2.7089e+02, 4.2169e+02, 3.0882e+02, 4.2215e+02],\n",
       "          [7.1258e+01, 1.9448e+01, 6.4000e+02, 2.1293e+01],\n",
       "          [3.1178e+02, 0.0000e+00, 6.3072e+02, 3.8915e+00],\n",
       "          [3.0841e+02, 4.1691e+02, 3.3619e+02, 4.1729e+02],\n",
       "          [2.4953e+02, 2.2858e+02, 2.8083e+02, 2.2898e+02],\n",
       "          [3.8633e+02, 3.4816e+02, 4.1276e+02, 3.4856e+02],\n",
       "          [4.3827e+02, 3.1200e+02, 4.7683e+02, 3.1228e+02],\n",
       "          [3.2010e+02, 1.5965e+01, 6.4000e+02, 1.8786e+01],\n",
       "          [1.5180e+02, 1.9853e+02, 6.1704e+02, 2.0157e+02],\n",
       "          [1.9781e+02, 6.4067e+00, 6.4000e+02, 1.0647e+01],\n",
       "          [2.8506e+02, 4.1030e+00, 6.3935e+02, 7.6934e+00],\n",
       "          [5.0329e+02, 4.1584e+02, 5.4290e+02, 4.1640e+02],\n",
       "          [2.9826e+02, 3.0805e+02, 3.3311e+02, 3.0838e+02],\n",
       "          [2.5599e+02, 2.3760e+02, 2.8520e+02, 2.3801e+02],\n",
       "          [4.0974e+02, 1.4584e+02, 4.3709e+02, 1.4633e+02],\n",
       "          [0.0000e+00, 1.3099e+01, 5.2522e+02, 1.6227e+01],\n",
       "          [5.2709e+02, 1.8563e+02, 5.5465e+02, 1.8603e+02],\n",
       "          [0.0000e+00, 2.1376e+02, 3.0173e+02, 2.1744e+02],\n",
       "          [2.8729e+02, 1.3442e+01, 6.4000e+02, 1.6055e+01],\n",
       "          [0.0000e+00, 3.1118e+02, 3.1163e+02, 3.1471e+02],\n",
       "          [5.3323e+02, 3.3530e+02, 5.6461e+02, 3.3572e+02],\n",
       "          [4.5506e+02, 2.7728e+02, 4.8016e+02, 2.7760e+02],\n",
       "          [1.0872e+02, 0.0000e+00, 5.9421e+02, 1.3045e+00],\n",
       "          [2.9531e+02, 2.9946e+02, 3.2247e+02, 2.9984e+02],\n",
       "          [4.3777e+02, 4.1268e+02, 4.6811e+02, 4.1299e+02],\n",
       "          [3.5746e+02, 3.4768e+02, 3.9378e+02, 3.4809e+02],\n",
       "          [4.0369e+02, 2.6619e+02, 4.3017e+02, 2.6650e+02],\n",
       "          [3.7876e+02, 1.1029e+02, 4.0239e+02, 1.1055e+02],\n",
       "          [3.7310e+02, 1.4566e+02, 4.0185e+02, 1.4597e+02],\n",
       "          [3.5018e+02, 0.0000e+00, 6.4000e+02, 1.7674e+00],\n",
       "          [5.1686e+02, 4.1732e+02, 5.5213e+02, 4.1774e+02],\n",
       "          [5.1436e+02, 4.2027e+02, 5.5075e+02, 4.2065e+02],\n",
       "          [3.1501e+02, 3.9444e+02, 3.5055e+02, 3.9477e+02]],\n",
       "         grad_fn=<StackBackward0>),\n",
       "  'labels': tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "          16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "          16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "          16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "          16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "          16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       "  'scores': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "          0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "          0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "          0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "          0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "          0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "          0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "          0.9999], grad_fn=<IndexBackward0>),\n",
       "  'masks': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          ...,\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "  \n",
       "  \n",
       "          [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            ...,\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "            [0., 0., 0.,  ..., 0., 0., 0.]]]], grad_fn=<UnsqueezeBackward0>)}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.rand(1, 3, 480, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f6c7a8-7cda-4d13-91e3-ebbf7051a2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Args:\n",
       "    images (list[Tensor]): images to be processed\n",
       "    targets (list[Dict[str, Tensor]]): ground-truth boxes present in the image (optional)\n",
       "\n",
       "Returns:\n",
       "    result (list[BoxList] or dict[Tensor]): the output from the model.\n",
       "        During training, it returns a dict[Tensor] which contains the losses.\n",
       "        During testing, it returns list[BoxList] contains additional fields\n",
       "        like `scores`, `labels` and `mask` (for Mask R-CNN models).\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/mlisuct/lib/python3.8/site-packages/torchvision/models/detection/generalized_rcnn.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.forward?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e6360-3896-4c19-a69c-0f5fcee1c8f2",
   "metadata": {},
   "source": [
    "# Проблемы с памятью\n",
    "\n",
    "- Модели для сегментации (и не только) могут быть прожорливы по памяти по сравнению с классификацией\n",
    "-- Больше карт активаций (encoder + decoder)\n",
    "-- Больше HW \n",
    "- Увеличивается потребление памяти на 1 пример -> уменьшается размер батча\n",
    "- Малый размер батча\n",
    "-- Шумные градиенты\n",
    "-- Проблемы с BatchNorm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2001398a-9f6b-43e6-be0d-cbf774370492",
   "metadata": {},
   "source": [
    "## Шумные градиенты для малых батчей\n",
    "\n",
    "- <a href=\"https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/02/19/gradient-accumulation.html\">Gradient Accumulation</a>\n",
    "- Накапливание градиентов по нескольким батчам перед обновлением весов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b00f518b-dc30-4581-8bb3-e80e8bf193bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28063/2741212790.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# loop through enumaretad batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# extract inputs and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# batch accumulation parameter\n",
    "accum_iter = 4  \n",
    "\n",
    "# loop through enumaretad batches\n",
    "for batch_idx, (inputs, labels) in enumerate(data_loader):\n",
    "\n",
    "    # extract inputs and labels\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "        \n",
    "    # forward pass \n",
    "    preds = model(inputs)\n",
    "    loss  = criterion(preds, labels)\n",
    "\n",
    "    # normalize loss to account for batch accumulation\n",
    "    loss = loss / accum_iter \n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # weights update\n",
    "    if ((batch_idx + 1) % accum_iter == 0) or (batch_idx + 1 == len(data_loader)):\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486a11a2-8dc1-4c01-98d5-2482f208d9ca",
   "metadata": {},
   "source": [
    "## Проблемы с BatchNorm\n",
    "\n",
    "- BN вычисляет статистики по батчу\n",
    "- Попался выброс в малом батче - сильно смещаются статистики\n",
    "- Решение\n",
    "-- Не использовать BN (-> InstanceNorm, …)\n",
    "-- Использовать много GPU + SynchronizedBN\n",
    "-- Если делаете fine-tuning: заморозить слои BN\n",
    "-- Оптимизировать вычисления для BN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8dd2b-cee9-4b08-9d0e-8e78f70738b4",
   "metadata": {},
   "source": [
    "### Оптимизация вычислений batch norm\n",
    "\n",
    "Recap:\n",
    "\n",
    "<img src=\"./img/batch_normalization.png\">\n",
    "\n",
    "- Для обновления параметров слоя требуется хранить тензор x после forward pass в буфере\n",
    "- При backward pass значение x извлекается из буфера\n",
    "- Есть подходы, избавляющие от этой необходимости\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239172ac-4876-4377-8629-0e61fe8fd96f",
   "metadata": {},
   "source": [
    "### Inplace-ABN (2018)\n",
    "\n",
    "- <a href=\"https://paperswithcode.com/paper/in-place-activated-batchnorm-for-memory\">In-Place Activated BN for Memory-Optimized Training of DNNs</a>\n",
    "- Рассмотрим связку BN + Activation + Conv\n",
    "\n",
    "<img src=\"./img/stand_build_block.png\">\n",
    "\n",
    "- Для backward pass необходимо хранить только промежуточные тензоры x, z\n",
    "-- Для обратимых активаций вроде Sigmoid/Tanh y восстанавливается по z\n",
    "-- Для ReLU по z нельзя восстановить y, но легко восстановить градиент dz/dy\n",
    "\n",
    "\n",
    "\n",
    "- Если после forward pass буферизовать только x, то по сохраненным статистикам BN можно вычислить заново y и затем z \n",
    "- Меньше памяти, больше вычислений\n",
    "- Нелокальность вычислений\n",
    "- <a href=\"https://pytorch.org/docs/stable/checkpoint.html\">Pytorch Checkpointing Doc</a>\n",
    "\n",
    "<img src=\"./img/check_build_block.png\">\n",
    "\n",
    "- Будем использовать только обратимые активации (LeakyReLu вместо ReLu)\n",
    "- Тогда можно при forward pass хранить только z\n",
    "- Вычисления теперь локальны \n",
    "\n",
    "<img src=\"./img/inb_prop_block.png\">\n",
    "\n",
    "- Заявленная авторами экономия памяти GPU: до 50%\n",
    "- Можно комбинировать с <a href=\"https://github.com/mapillary/inplace_abn/blob/main/inplace_abn/abn.py\">SyncBN</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a8a16c-297d-4cff-aeda-2acd3d1e02ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
