{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf13759-df75-4d78-8ff4-63d4db49bdee",
   "metadata": {},
   "source": [
    "# Network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112de3fc-6f34-4637-a940-f0e486dcc8fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Softmax\n",
    "\n",
    "Итак мы выяснили как тренировать нашу нейронную сеть когда мы делаем предсказание регрессии или классификации на один класс, а что если классов несколько, например набор данных MNIST содержит 10 классов, по одному на каждую из цифр\n",
    "\n",
    "В этом случае, во-первых мы будем иметь несколько выходов из нашей сети, по одному на каждый класс\n",
    "\n",
    "<img src=\"img/dense.png\" style=\"background-color:white;\">\n",
    "\n",
    "Понятно что выходы могут иметь любое выходное значение, в зависимости от весов сети, однако мы хотели бы получить распеределение вероятностей для каждого из классов.\n",
    "\n",
    "Тогда нам нужно нормализовать выходы, чтобы их сумма равнялась 1, делают это с помощью Softmax\n",
    "\n",
    "$$\\large{S(z_j) =  \\frac{e^{z_j}}{\\sum_{i}^{C} e^{z_i}}}$$\n",
    "\n",
    "Где j - индекс искомого класса, C - количество классов в датасете\n",
    "\n",
    "Давайте рассмотрим градиент этой функции по z_k\n",
    "\n",
    "Для простоты вычислений воспользуемся небольшим трюком:\n",
    "\n",
    "$$\\large{\\frac{\\partial log(f(x))}{\\partial x} = \\frac{\\partial f(x)}{\\partial x} \\frac{1}{f(x)}}$$\n",
    "\n",
    "$$\\large{f(x)\\frac{\\partial log(f(x))}{\\partial x} = \\frac{\\partial f(x)}{\\partial x}}$$\n",
    "\n",
    "Раскроем логарифм поверх Softmax\n",
    "\n",
    "$$\\large{log(S(z_j))} = log(\\frac{e^{z_j}}{\\sum_{i}^{C} e^{z_i}}) = z_j - log(\\sum_{i}^{C} e^{z_i})))$$\n",
    "\n",
    "Производная от z_j равна 1 если j == k, иначе она равна нулю, запишем это через индексную функцию\n",
    "\n",
    "$$\\large{\\frac{\\partial log(S(z_j))}{\\partial z_k} = \\mathbb{1}[k == j] - \\frac{\\partial log(\\sum_{i}^{C} e^{z_i}))}{\\partial z_k}}$$\n",
    "\n",
    "Производная под логарифмом не нулевая только $e^{z_k}$\n",
    "\n",
    "$$\\large{\\frac{\\partial log(S(z_j))}{\\partial z_k} = \\mathbb{1}[k == j] - \\frac{e^{z_k}}{\\sum_{i}^{C} e^{z_i}}}$$\n",
    "\n",
    "Заметим что справа у нас опять стоит Softmax только на этот раз от k\n",
    "\n",
    "$$\\large{\\frac{\\partial log(S(z_j))}{\\partial z_k} = \\mathbb{1}[k == j] - S(z_k)}$$\n",
    "\n",
    "Возвратим градиент функции по трюку которым мы воспользовались\n",
    "\n",
    "$$\\large{\\frac{\\partial S(z_j)}{\\partial z_k} = S(z_j)(\\mathbb{1}[k == j] - S(z_k))}$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\large{\\frac{\\partial S(z_j)}{\\partial z_k} = \n",
    "\\begin{equation}\n",
    "    \\begin{cases}\n",
    "      S(z_j)(1 - S(z_j)), & \\mbox{if k==j}\\\\\n",
    "      -S(z_j)S(z_k), & \\mbox{if k!=j}\n",
    "    \\end{cases}\\,.\n",
    "\\end{equation}\n",
    "}\n",
    "$$\n",
    "\n",
    "\n",
    "## 2. Cross Entropy\n",
    "\n",
    "Однако, нам так же нужно обновить и функцию потерь на многоклассовый случай. Воспользуемся выводами из BCE и применим их на многоклассовый выход\n",
    "\n",
    "В данном случае $y_i$ будет OHE вектором класса\n",
    "\n",
    "$$\\large{L = -\\sum_i^C y_i log(S(z_i))}$$\n",
    "\n",
    "Давайте посмотрим на градиент этой функции\n",
    "\n",
    "$$\\large{\\frac{\\partial L}{\\partial z_k} = -\\sum_i^C y_i \\frac{\\partial log(S(z_i))}{\\partial z_k}}$$\n",
    "\n",
    "$$\\large{\\frac{\\partial L}{\\partial z_k} = -\\sum_i^C y_i \\frac{\\partial S(z_i)}{\\partial z_k} \\frac{1}{S(z_i)}}$$\n",
    "\n",
    "Градиент по softmax мы вычислили ранее\n",
    "\n",
    "$$\\large{\\frac{\\partial L}{\\partial z_k} = -\\sum_i^C y_i S(z_i) (\\mathbb{1}[k == i] - S(z_k)) \\frac{1}{S(z_i)}}$$\n",
    "\n",
    "$$\\large{\\frac{\\partial L}{\\partial z_k} = -\\sum_i^C y_i (\\mathbb{1}[k == i] - S(z_k))}$$\n",
    "\n",
    "$$\\large{\\frac{\\partial L}{\\partial z_k} = -\\sum_i^C \\mathbb{1}[k == i] y_i +\\sum_i^C S(z_k) y_i}$$\n",
    "\n",
    "$$\\large{\\frac{\\partial L}{\\partial z_k} = -y_k + S(z_k) \\sum_i^C y_i}$$\n",
    "\n",
    "Воспользуймся фактом что сумма OHE векторов всех классов равна единичному\n",
    "\n",
    "$$\\large{\\frac{\\partial L}{\\partial z_k} = S(z_k) - y_k}$$\n",
    "\n",
    "Часто для удобства вычислений градиента Cross Entropy объеденяют с Softmax в одну функцию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d068f623-84e1-4ad5-a22e-3f71f9ef016b",
   "metadata": {},
   "source": [
    "## 3. Градиентный спуск\n",
    "\n",
    "Вспомним как бы делали градиентный спуск в модели линейной регресии, мы расчитывали функцию потерь для всех входящих векторов и суммировали их\n",
    "\n",
    "Градиентный спуск был достаточно медленным алгоритмом, однако он хорошо искал минимум фукнции\n",
    "\n",
    "С другой стороны мы знаем про стохастический градиентный спуск, когда мы выбираем случайный вектор и считаем функцию потерь относительно него\n",
    "\n",
    "Стохастический градиентный спуск был очень быстрым алгоримом, но не всегда искал хороший минимум\n",
    "\n",
    "В данном курсе мы будем пользоваться средним вариантом Batch Gradient Descent - когда мы выбираем несколько случайных векторов и считаем функцию потерь относительно них\n",
    "\n",
    "<img src=\"img/bgd.jpeg\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98374b5-c102-4d6d-8df9-cf401e1761d0",
   "metadata": {},
   "source": [
    "## 4. Оптимизация градиентного спуска\n",
    "\n",
    "### 4.1 Momentum\n",
    "\n",
    "![without_momentum](img/without_momentum.gif \"without_segment\")\n",
    "![with_momentum](img/with_momentum.gif \"with_segment\")\n",
    "\n",
    "Идея данной оптимизации состоит в том что мы сохраняем направление предыдущего шага и новый шаг делаем учитывая старое направление, таким образом мы уменьшаем влияние шумных признаков на оптимизацию\n",
    "\n",
    "$$\\large{\\upsilon_t = \\gamma \\upsilon_{t-1} + \\eta \\nabla_{W} J(W)}$$\n",
    "$$\\large{W = W - \\upsilon_t}$$\n",
    "\n",
    "$\\gamma$ - гиперпараметр алгорима, чем он больше, тем сильнее учитывается направление предыдущего шага, обычно $\\gamma = 0.9$\n",
    "\n",
    "Визуально можно представить шарик катящийся с горки по неровной дороге, он переодически отклоняется то влево то вправо, однако основное ускорение направленно вниз"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ea6639-a7fe-4b72-b07e-c65aa7a75779",
   "metadata": {},
   "source": [
    "### 4.2 Nesterov accelerated gradient\n",
    "\n",
    "У метода momentum есть существенный недостаток, то что мы можем проскочить точку оптимума из-за того что двигались слишком быстро в направлении предыдущего шага, попробуем это решить \n",
    "\n",
    "$$\\large{\\upsilon_t = \\gamma \\upsilon_{t-1} + \\eta \\nabla_{W} J(W - \\gamma \\upsilon_{t-1})}$$\n",
    "$$\\large{W = W - \\upsilon_t}$$\n",
    "\n",
    "![nesterov](img/nesterov_update_vector.png)\n",
    "\n",
    "Итак momentum считает направление текущего градиента (маленький синий вектор), а после делает большой скачок в направлении предыдущего шага (большой коричневый вектор)\n",
    "\n",
    "NAG в свою очередь сначала делает скачок в направлении предущего шага, а после корректирует его (маленький красный вектор), что дает зеленый вектор\n",
    "\n",
    "Теперь, когда мы можем адаптировать наши обновления к наклону нашей функции ошибок и ускорить SGD, мы также хотели бы адаптировать наши обновления к каждому отдельному параметру, чтобы делать обновления в зависимости от их важности параметра."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3265e320-a807-4fed-8513-1ff4b3e766d6",
   "metadata": {},
   "source": [
    "### 4.3 Adagrad\n",
    "\n",
    "Adagrad — это алгоритм оптимизации, который делает именно то что мы хотели: адаптирует скорость обучения к параметрам, выполняя небольшие обновления для параметров которые встречаются часто, и более крупные обновления для редко встречаемых параметров. Он делает это оптимизируя скорость обучения под параметры\n",
    "\n",
    "Итак определим $g_{t, i}$ как градиент в момент времени t для функции потерь по параметру сети i:\n",
    "\n",
    "$$\\large{g_{t,i} = \\nabla_WJ(W_{t,i})}$$\n",
    "\n",
    "Тогда обновления параметра сети в момент времени t, для SGD:\n",
    "\n",
    "$$\\large{W_{t+1,i} = W_{t,i} - \\eta g_{t +1, i}}$$\n",
    "\n",
    "Правило обновления параметров Adagrad изменяет скорость обучения на каждом шаге обновления, для каждого параметра, базируесь на прошлом значении градиента параметра:\n",
    "\n",
    "$$\\large{\\theta_{t+1,i} = \\theta_{t,i} - \\frac{\\eta}{\\sqrt{G_{t,ii} + \\epsilon}} g_{t, i}}$$\n",
    "\n",
    "$G_{t,ii} \\in R ^ {d x d}$ -диагональная матрица где на диагонали находится сумма квадратов параметров $W_i$ в момент времени t, $\\epsilon$ - небольшая константа чтобы избежать деления на ноль, обычно 1e-8\n",
    "\n",
    "Чтобы избавится от номера параметра i перепишем в матричном виде\n",
    "\n",
    "$$\\large{\\theta_{t+1} = \\theta_{t} - \\frac{\\eta}{\\sqrt{G_{t} + \\epsilon}} \\bigodot g_{t}}$$\n",
    "\n",
    "$\\bigodot$ - матрично-векторное произведение\n",
    "\n",
    "Главный недостаток Adagrad это накопление суммы градиента в знаменателе и чем дальше по времени мы движемся, тем более несущественными становятся наши обновления"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b8b93-a8ab-4a07-861c-20e72f3a9eea",
   "metadata": {},
   "source": [
    "### 4.4 Adadelta\n",
    "\n",
    "Adadelta - это улучшение Adagrad призванное уменьшить слишком быстрое снижение скорости обновления, adadelta сужает аккумулирование градиента вместо всей временной шкалы до окна $\\omega$\n",
    "\n",
    "Вместо неэффективного хранения значений $\\omega$ сумм предыдущих квадратов градиентов, мы будем считать экспонентоциальное среднее значений $E[g^2]_t$, в такой постановке наше значение $E[g^2]_t$ опирается лишь на текущий градиент и предыдущее значение:\n",
    "\n",
    "$$\\large{E[g^2]_{t} = \\gamma E[g^2]_{t - 1} + (1 - \\gamma) g^2_t}$$\n",
    "\n",
    "Мы будем использовать $\\gamma$ близкую к значение в momentum (около 0.9)\n",
    "\n",
    "Перепишем обновление SGD через $\\Delta W_t$\n",
    "\n",
    "$$\\large{\\Delta W_t} = -\\eta g_t$$\n",
    "\n",
    "$$\\large{W_{t+1}} = W_t + \\Delta W_t$$\n",
    "\n",
    "В Adagrad мы определили $\\Delta W_t$ как \n",
    "\n",
    "$$\\large{\\Delta W_t} = - \\frac{\\eta}{\\sqrt{G_{t} + \\epsilon}} \\bigodot g_{t}$$\n",
    "\n",
    "Теперь вместо $G_t$ мы используем $E[g^2]_t$\n",
    "\n",
    "$$\\large{\\Delta W_t} = - \\frac{\\eta}{\\sqrt{E[g^2]_t + \\epsilon}} g_{t}$$\n",
    "\n",
    "Заметим что знаменатель это RMSE\n",
    "\n",
    "$$\\large{\\Delta W_t} = - \\frac{\\eta}{RMS[g_t]} g_{t}$$\n",
    "\n",
    "Авторы отмечают что в этом методе (а так же всех предыдущих), единицы величины части обновления отличаются от единиц параметра, чтобы исправить это они предложили высчитывать экспонентоциальное среднее изменения параметра а не самих параметров\n",
    "\n",
    "$$\\large{E[\\Delta W^2]_{t} = \\gamma E[\\Delta W^2]_{t - 1} + (1 - \\gamma) \\Delta W^2_t}$$\n",
    "\n",
    "$$\\large{RMS[\\Delta W_t] = \\sqrt{E[\\Delta W^2]_{t} + \\epsilon}}$$\n",
    "\n",
    "Поскольку $RMS[\\Delta W_t]$ нам неизвестен на шаге t мы апроксимируем его через RMS от обновления параметров на предыдущем шаге. Замета $\\eta$ в формуле обновления наконец то даст нам Adadelta\n",
    "\n",
    "$$\\large{\\Delta W_t} = - \\frac{RMS[\\Delta W_{t-1}]}{RMS[g_t]} g_{t}$$\n",
    "\n",
    "$$\\large{W_{t+1}} = W_t + \\Delta W_t$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c315b0-4c57-4138-8d66-0fbc7c9a0e3e",
   "metadata": {},
   "source": [
    "### 4.5 RMSprop\n",
    "\n",
    "RMSprop — это неопубликованный метод адаптивной скорости обучения.\n",
    "\n",
    "RMSprop и Adadelta были разработаны независимо друг от друга примерно в одно и то же время из-за необходимости решить проблему радикального снижения скорости обучения в Adagrad. Фактически RMSprop идентичен первому вектору обновления Adadelta, который мы получили выше:\n",
    "\n",
    "$$\\large{E[g^2]_{t} = \\gamma E[g^2]_{t - 1} + (1 - \\gamma) g^2_t}$$\n",
    "\n",
    "$$\\large{W_t} = W_t - \\frac{\\eta}{\\sqrt{E[g^2]_t + \\epsilon}} g_{t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17574b7-6360-45dd-9c61-7f5294dbf5b4",
   "metadata": {},
   "source": [
    "### 4.6 Adam\n",
    "\n",
    "Adaptive Moment Estimation (Adam) — это еще один метод, который вычисляет скорость адаптивного обучения для каждого параметра. В дополнение к хранению экспоненциально затухающих средних значений прошлых квадратов градиентов $\\upsilon_t$ подобно Adadelta и RMSprop, Адам также хранит экспоненциально затухающие средние значения прошлых градиентов.\n",
    "\n",
    "$$\\large{m_t = \\beta_1 m_{t-1} + (1 - \\beta_1)g_t}$$\n",
    "$$\\large{\\upsilon_t = \\beta_2 \\upsilon_{t-1} + (1 - \\beta_2)g^2_t}$$\n",
    "\n",
    "$m_t$ и $\\upsilon_t$ приближают первый момент (среднее) и второй момент (смещенную дисперсию) параметров соотвественно\n",
    "\n",
    "Поскольку $m_t$ и $\\upsilon_t$ инициализируются как нулевые вектора, у нас имеется проблема что при больших значениях $\\beta_1$ и $\\beta_2$ $m_t$ и $\\upsilon_t$ в начальных шагах близки к нулю\n",
    "\n",
    "Поэтому будем использовать их исправленные версии\n",
    "\n",
    "$$\\large{\\hat{m_t} = \\frac{m_t}{1 - \\beta_1}}$$\n",
    "$$\\large{\\hat{\\upsilon_t} = \\frac{\\upsilon_t}{1 - \\beta_2}}$$\n",
    "\n",
    "Правило обновления схоже с Adadelta и RMSProp\n",
    "\n",
    "$$\\large{W_{t+1} = W_t - \\frac{\\eta}{\\sqrt{\\hat{\\upsilon_t}} + \\epsilon}\\hat{m_t}}$$\n",
    "\n",
    "Авторы метода рекомендуют использовать параметры $\\beta_1 = 0.9$, $\\beta_2 = 0.999$ и $\\epsilon = 1e-8$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e98f614-79c3-4096-ac8e-ff22f63e2304",
   "metadata": {},
   "source": [
    "## 5. Инициализация весов\n",
    "\n",
    "Итак мы знаем как оптимизировать обучение нейронной сети, как текут градиенты и как решать задачи классификации и регрессии, но что же делать с весами\n",
    "\n",
    "Стандарная инициализация 0 не очень хороша, поскольку начальные градиенты будут занулятся и мы будем начинать обучение достаточно долго\n",
    "\n",
    "Другой вариант инициализировать весами из нормального распределения с нулевым смещением и какой дисперсией, данный вариант гораздо лучше: поскольку наши градиенты не зануляются и обучение стартует быстрее, но есть обратная проблема что они могут стать слишком большими из-за большого количества умножений\n",
    "\n",
    "### 5.1 Xavier weight initialization\n",
    "метод предложенный для ускорения обучения особой инициализиацией весов, их существует несколько вариантов\n",
    "\n",
    "1. Семплирование из равномерного распределения зависящего от количества входных признаков в слой\n",
    "\n",
    "$$\\large{W \\sim U[-\\frac{1}{\\sqrt{n}}, \\frac{1}{\\sqrt{n}}]}$$\n",
    "\n",
    "2. Семплирование из равномерного распределения зависящего от количества входных и выходных признаков в слой\n",
    "\n",
    "$$\\large{W \\sim U[-\\sqrt{\\frac{6}{n + m}}, \\sqrt{\\frac{6}{n + m}}]}$$\n",
    "\n",
    "Чем такая инициализация лучше - тем что мы уменьшаем величину весов в зависимости от размера слоя и наши градиенты не становятся слишком большими\n",
    "\n",
    "### 5.2 He weight Initialization\n",
    "\n",
    "метод инициализации для сетей с ReLu слоем\n",
    "\n",
    "1. Семплирование из нормального распередления в зависимости от количества входных признаков\n",
    "$$\\large{W \\sim N[0, \\sqrt{\\frac{2}{n}}]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "919f5e29-9837-4e62-a113-0c681999cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def init_xavier_input(input_size, output_size):\n",
    "    value = np.sqrt(1 / input_size)\n",
    "    return np.random.uniform(-value, value, size=(input_size, output_size))\n",
    "\n",
    "\n",
    "def init_xavier_input_output(input_size, output_size):\n",
    "    value = np.sqrt(6 / (input_size + output_size))\n",
    "    return np.random.uniform(-value, value, size=(input_size, output_size))\n",
    "\n",
    "\n",
    "def init_he_input(input_size, output_size):\n",
    "    sigma = np.sqrt(2 / input_size)\n",
    "    return np.random.normal(0, sigma, size=(input_size, output_size))\n",
    "\n",
    "\n",
    "class LinearLayer:\n",
    "    \n",
    "    def __init__(self, input_size, output_size, initalization):\n",
    "        \n",
    "        self.weights = initalization(input_size, output_size)\n",
    "        self.biases = np.zeros(output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b0dcf8f-7a8d-4d65-9634-8f41b854c224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer = LinearLayer(28 * 28, 256, init_xavier_input)\n",
    "\n",
    "sns.displot(layer.weights.flatten());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "698a3227-d6ba-478c-9631-d30b9141ec10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer = LinearLayer(28 * 28, 256, init_xavier_input_output)\n",
    "\n",
    "sns.displot(layer.weights.flatten());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5a96cf6-e81e-4bcc-8b97-ade0630dde96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer = LinearLayer(28 * 28, 256, init_he_input)\n",
    "\n",
    "sns.displot(layer.weights.flatten());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89bef615-67c6-4ecb-9feb-335e546036b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LinearLR, ExponentialLR, CosineAnnealingLR, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0173b83-44d5-4e3b-a4e0-884ec398c8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mthreshold_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rel'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcooldown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmin_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-08\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Reduce learning rate when a metric has stopped improving.\n",
       "Models often benefit from reducing the learning rate by a factor\n",
       "of 2-10 once learning stagnates. This scheduler reads a metrics\n",
       "quantity and if no improvement is seen for a 'patience' number\n",
       "of epochs, the learning rate is reduced.\n",
       "\n",
       "Args:\n",
       "    optimizer (Optimizer): Wrapped optimizer.\n",
       "    mode (str): One of `min`, `max`. In `min` mode, lr will\n",
       "        be reduced when the quantity monitored has stopped\n",
       "        decreasing; in `max` mode it will be reduced when the\n",
       "        quantity monitored has stopped increasing. Default: 'min'.\n",
       "    factor (float): Factor by which the learning rate will be\n",
       "        reduced. new_lr = lr * factor. Default: 0.1.\n",
       "    patience (int): Number of epochs with no improvement after\n",
       "        which learning rate will be reduced. For example, if\n",
       "        `patience = 2`, then we will ignore the first 2 epochs\n",
       "        with no improvement, and will only decrease the LR after the\n",
       "        3rd epoch if the loss still hasn't improved then.\n",
       "        Default: 10.\n",
       "    threshold (float): Threshold for measuring the new optimum,\n",
       "        to only focus on significant changes. Default: 1e-4.\n",
       "    threshold_mode (str): One of `rel`, `abs`. In `rel` mode,\n",
       "        dynamic_threshold = best * ( 1 + threshold ) in 'max'\n",
       "        mode or best * ( 1 - threshold ) in `min` mode.\n",
       "        In `abs` mode, dynamic_threshold = best + threshold in\n",
       "        `max` mode or best - threshold in `min` mode. Default: 'rel'.\n",
       "    cooldown (int): Number of epochs to wait before resuming\n",
       "        normal operation after lr has been reduced. Default: 0.\n",
       "    min_lr (float or list): A scalar or a list of scalars. A\n",
       "        lower bound on the learning rate of all param groups\n",
       "        or each group respectively. Default: 0.\n",
       "    eps (float): Minimal decay applied to lr. If the difference\n",
       "        between new and old lr is smaller than eps, the update is\n",
       "        ignored. Default: 1e-8.\n",
       "    verbose (bool): If ``True``, prints a message to stdout for\n",
       "        each update. Default: ``False``.\n",
       "\n",
       "Example:\n",
       "    >>> # xdoctest: +SKIP\n",
       "    >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
       "    >>> scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
       "    >>> for epoch in range(10):\n",
       "    >>>     train(...)\n",
       "    >>>     val_loss = validate(...)\n",
       "    >>>     # Note that step should be called after validate()\n",
       "    >>>     scheduler.step(val_loss)\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\anesterenko\\miniconda3\\envs\\mlisuct\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ReduceLROnPlateau?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c72394-ba26-475e-a7f7-4488808cb1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
